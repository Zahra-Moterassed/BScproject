{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ECOD 2022\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.ecod import ECOD\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_ecod_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the ECOD model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply ECOD from pyod\n",
    "    ecod = ECOD()\n",
    "    ecod.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = ecod.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_ecod_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate ECOD outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.051094890510948905\n",
      "Recall: 0.25925925925925924\n",
      "AUC: 0.738047642845244\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.26530612244897955\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.058823529411764705\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8679718875502008\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "outlier_scores = calculate_ecod_outlier_scores(data)\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(outlier_scores, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COPOD 2020\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.copod import COPOD\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_copod_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the COPOD model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply COPOD from pyod\n",
    "    copod = COPOD()\n",
    "    copod.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = copod.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_copod_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate ECOD outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.051094890510948905\n",
      "Recall: 0.25925925925925924\n",
      "AUC: 0.6914598256427342\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.40816326530612246\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.058823529411764705\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.7966867469879517\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "outlier_scores = calculate_copod_outlier_scores(data)\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(outlier_scores, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.09090909090909091\n",
      "Recall: 0.5\n",
      "AUC: 0.605\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROD 2020\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.rod import ROD\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_rod_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the ROD model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply ROD from pyod\n",
    "    rod = ROD()\n",
    "    rod.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = rod.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_rod_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate ECOD outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.072992700729927\n",
      "Recall: 0.37037037037037035\n",
      "AUC: 0.7775556666111388\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(data, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mlabels, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate outlier scores on the training set\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m predicted_outlier_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_rod_outlier_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Evaluate the performance on the validation set\u001b[39;00m\n\u001b[0;32m     27\u001b[0m val_outlier_scores \u001b[38;5;241m=\u001b[39m calculate_rod_outlier_scores(X_val)\n",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m, in \u001b[0;36mcalculate_rod_outlier_scores\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Apply ROD from pyod\u001b[39;00m\n\u001b[0;32m     18\u001b[0m rod \u001b[38;5;241m=\u001b[39m ROD()\n\u001b[1;32m---> 19\u001b[0m \u001b[43mrod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Get the outlier scores\u001b[39;00m\n\u001b[0;32m     22\u001b[0m outlier_scores \u001b[38;5;241m=\u001b[39m rod\u001b[38;5;241m.\u001b[39mdecision_scores_  \u001b[38;5;66;03m# higher score -> more outlier\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:407\u001b[0m, in \u001b[0;36mROD.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=404'>405</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler1_ \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# scaler(s) of Angles Group 1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=405'>406</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler2_ \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# scaler(s) of Angles Group 2\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=406'>407</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_scores_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=407'>408</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_decision_scores()\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=409'>410</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:443\u001b[0m, in \u001b[0;36mROD.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=434'>435</a>\u001b[0m     scores, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgm_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmedian_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler1_, \\\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=435'>436</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler2_ \u001b[39m=\u001b[39m rod_3D(x\u001b[39m=\u001b[39mX, gm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgm_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=436'>437</a>\u001b[0m                                       median\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmedian_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=437'>438</a>\u001b[0m                                       scaler1\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler1_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=438'>439</a>\u001b[0m                                       scaler2\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler2_)\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=439'>440</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m scores\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=441'>442</a>\u001b[0m scores, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgm_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmedian_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_scaler_, \\\n\u001b[1;32m--> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=442'>443</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler1_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler2_ \u001b[39m=\u001b[39m rod_nD(X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=443'>444</a>\u001b[0m                                                         parallel\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_execution,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=444'>445</a>\u001b[0m                                                         gm\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgm_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=445'>446</a>\u001b[0m                                                         median\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmedian_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=446'>447</a>\u001b[0m                                                         data_scaler\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_scaler_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=447'>448</a>\u001b[0m                                                         angles_scalers1\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mangles_scaler1_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=448'>449</a>\u001b[0m                                                         angles_scalers2\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mangles_scaler2_)\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=449'>450</a>\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:316\u001b[0m, in \u001b[0;36mrod_nD\u001b[1;34m(X, parallel, gm, median, data_scaler, angles_scalers1, angles_scalers2)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=310'>311</a>\u001b[0m subspaces_scores, gm, median, angles_scalers1, angles_scalers2 \u001b[39m=\u001b[39m [], [], [], [], []\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=311'>312</a>\u001b[0m \u001b[39mfor\u001b[39;00m subspace, _gm, med, ang_s1, ang_s2 \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(all_subspaces, all_gms,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=312'>313</a>\u001b[0m                                               all_meds,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=313'>314</a>\u001b[0m                                               all_angles_scalers1,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=314'>315</a>\u001b[0m                                               all_angles_scalers2):\n\u001b[1;32m--> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=315'>316</a>\u001b[0m     scores_, gm_, med_, ang_s1_, ang_s2_ \u001b[39m=\u001b[39m process_sub(subspace\u001b[39m=\u001b[39;49msubspace,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=316'>317</a>\u001b[0m                                                        gm\u001b[39m=\u001b[39;49m_gm, median\u001b[39m=\u001b[39;49mmed,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=317'>318</a>\u001b[0m                                                        scaler1\u001b[39m=\u001b[39;49mang_s1,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=318'>319</a>\u001b[0m                                                        scaler2\u001b[39m=\u001b[39;49mang_s2)\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=319'>320</a>\u001b[0m     subspaces_scores\u001b[39m.\u001b[39mappend(scores_)\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=320'>321</a>\u001b[0m     gm\u001b[39m.\u001b[39mappend(gm_)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:245\u001b[0m, in \u001b[0;36mprocess_sub\u001b[1;34m(subspace, gm, median, scaler1, scaler2)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=227'>228</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_sub\u001b[39m(subspace, gm, median, scaler1, scaler2):\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=228'>229</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=229'>230</a>\u001b[0m \u001b[39m    Apply ROD on a 3D subSpace then process it with sigmoid\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=230'>231</a>\u001b[0m \u001b[39m    to compare apples to apples\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=242'>243</a>\u001b[0m \u001b[39m    ROD decision scores with sigmoid applied, gm, scaler1, scaler2\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=243'>244</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=244'>245</a>\u001b[0m     mad_subspace, gm, median, scaler1, scaler2 \u001b[39m=\u001b[39m rod_3D(subspace, gm\u001b[39m=\u001b[39;49mgm,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=245'>246</a>\u001b[0m                                                         median\u001b[39m=\u001b[39;49mmedian,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=246'>247</a>\u001b[0m                                                         scaler1\u001b[39m=\u001b[39;49mscaler1,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=247'>248</a>\u001b[0m                                                         scaler2\u001b[39m=\u001b[39;49mscaler2)\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=248'>249</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m sigmoid(\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=249'>250</a>\u001b[0m         np\u001b[39m.\u001b[39mnan_to_num(np\u001b[39m.\u001b[39marray(mad_subspace))), gm, median, scaler1, scaler2\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:196\u001b[0m, in \u001b[0;36mrod_3D\u001b[1;34m(x, gm, median, scaler1, scaler2)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=177'>178</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=178'>179</a>\u001b[0m \u001b[39mFind ROD scores for 3D Data.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=179'>180</a>\u001b[0m \u001b[39mnote that gm, scaler1 and scaler2 will be returned \"as they are\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=192'>193</a>\u001b[0m \u001b[39mdecision_scores, gm, scaler1, scaler2\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=193'>194</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=194'>195</a>\u001b[0m \u001b[39m# find the geometric median if it is not already fit\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=195'>196</a>\u001b[0m gm \u001b[39m=\u001b[39m geometric_median(x) \u001b[39mif\u001b[39;00m gm \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m gm\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=196'>197</a>\u001b[0m \u001b[39m# find its norm and center data around it\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=197'>198</a>\u001b[0m norm_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(gm)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:80\u001b[0m, in \u001b[0;36mgeometric_median\u001b[1;34m(x, eps)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=77'>78</a>\u001b[0m Dinvs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(Dinv)\n\u001b[0;32m     <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=78'>79</a>\u001b[0m W \u001b[39m=\u001b[39m Dinv \u001b[39m/\u001b[39m Dinvs\n\u001b[1;32m---> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=79'>80</a>\u001b[0m T \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(W \u001b[39m*\u001b[39m points[non_zeros], \u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=80'>81</a>\u001b[0m num_zeros \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(points) \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39msum(non_zeros)\n\u001b[0;32m     <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=81'>82</a>\u001b[0m \u001b[39mif\u001b[39;00m num_zeros \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(data, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mlabels, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate outlier scores on the training set\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m predicted_outlier_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_rod_outlier_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Evaluate the performance on the validation set\u001b[39;00m\n\u001b[0;32m     27\u001b[0m val_outlier_scores \u001b[38;5;241m=\u001b[39m calculate_rod_outlier_scores(X_val)\n",
      "Cell \u001b[1;32mIn[46], line 19\u001b[0m, in \u001b[0;36mcalculate_rod_outlier_scores\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Apply ROD from pyod\u001b[39;00m\n\u001b[0;32m     18\u001b[0m rod \u001b[38;5;241m=\u001b[39m ROD()\n\u001b[1;32m---> 19\u001b[0m \u001b[43mrod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Get the outlier scores\u001b[39;00m\n\u001b[0;32m     22\u001b[0m outlier_scores \u001b[38;5;241m=\u001b[39m rod\u001b[38;5;241m.\u001b[39mdecision_scores_  \u001b[38;5;66;03m# higher score -> more outlier\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:407\u001b[0m, in \u001b[0;36mROD.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=404'>405</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler1_ \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# scaler(s) of Angles Group 1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=405'>406</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler2_ \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# scaler(s) of Angles Group 2\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=406'>407</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_scores_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=407'>408</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_decision_scores()\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=409'>410</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:443\u001b[0m, in \u001b[0;36mROD.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=434'>435</a>\u001b[0m     scores, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgm_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmedian_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler1_, \\\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=435'>436</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler2_ \u001b[39m=\u001b[39m rod_3D(x\u001b[39m=\u001b[39mX, gm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgm_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=436'>437</a>\u001b[0m                                       median\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmedian_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=437'>438</a>\u001b[0m                                       scaler1\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler1_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=438'>439</a>\u001b[0m                                       scaler2\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler2_)\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=439'>440</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m scores\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=441'>442</a>\u001b[0m scores, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgm_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmedian_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_scaler_, \\\n\u001b[1;32m--> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=442'>443</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler1_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mangles_scaler2_ \u001b[39m=\u001b[39m rod_nD(X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=443'>444</a>\u001b[0m                                                         parallel\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_execution,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=444'>445</a>\u001b[0m                                                         gm\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgm_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=445'>446</a>\u001b[0m                                                         median\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmedian_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=446'>447</a>\u001b[0m                                                         data_scaler\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_scaler_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=447'>448</a>\u001b[0m                                                         angles_scalers1\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mangles_scaler1_,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=448'>449</a>\u001b[0m                                                         angles_scalers2\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mangles_scaler2_)\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=449'>450</a>\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:316\u001b[0m, in \u001b[0;36mrod_nD\u001b[1;34m(X, parallel, gm, median, data_scaler, angles_scalers1, angles_scalers2)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=310'>311</a>\u001b[0m subspaces_scores, gm, median, angles_scalers1, angles_scalers2 \u001b[39m=\u001b[39m [], [], [], [], []\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=311'>312</a>\u001b[0m \u001b[39mfor\u001b[39;00m subspace, _gm, med, ang_s1, ang_s2 \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(all_subspaces, all_gms,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=312'>313</a>\u001b[0m                                               all_meds,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=313'>314</a>\u001b[0m                                               all_angles_scalers1,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=314'>315</a>\u001b[0m                                               all_angles_scalers2):\n\u001b[1;32m--> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=315'>316</a>\u001b[0m     scores_, gm_, med_, ang_s1_, ang_s2_ \u001b[39m=\u001b[39m process_sub(subspace\u001b[39m=\u001b[39;49msubspace,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=316'>317</a>\u001b[0m                                                        gm\u001b[39m=\u001b[39;49m_gm, median\u001b[39m=\u001b[39;49mmed,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=317'>318</a>\u001b[0m                                                        scaler1\u001b[39m=\u001b[39;49mang_s1,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=318'>319</a>\u001b[0m                                                        scaler2\u001b[39m=\u001b[39;49mang_s2)\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=319'>320</a>\u001b[0m     subspaces_scores\u001b[39m.\u001b[39mappend(scores_)\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=320'>321</a>\u001b[0m     gm\u001b[39m.\u001b[39mappend(gm_)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:245\u001b[0m, in \u001b[0;36mprocess_sub\u001b[1;34m(subspace, gm, median, scaler1, scaler2)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=227'>228</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_sub\u001b[39m(subspace, gm, median, scaler1, scaler2):\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=228'>229</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=229'>230</a>\u001b[0m \u001b[39m    Apply ROD on a 3D subSpace then process it with sigmoid\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=230'>231</a>\u001b[0m \u001b[39m    to compare apples to apples\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=242'>243</a>\u001b[0m \u001b[39m    ROD decision scores with sigmoid applied, gm, scaler1, scaler2\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=243'>244</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=244'>245</a>\u001b[0m     mad_subspace, gm, median, scaler1, scaler2 \u001b[39m=\u001b[39m rod_3D(subspace, gm\u001b[39m=\u001b[39;49mgm,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=245'>246</a>\u001b[0m                                                         median\u001b[39m=\u001b[39;49mmedian,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=246'>247</a>\u001b[0m                                                         scaler1\u001b[39m=\u001b[39;49mscaler1,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=247'>248</a>\u001b[0m                                                         scaler2\u001b[39m=\u001b[39;49mscaler2)\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=248'>249</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m sigmoid(\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=249'>250</a>\u001b[0m         np\u001b[39m.\u001b[39mnan_to_num(np\u001b[39m.\u001b[39marray(mad_subspace))), gm, median, scaler1, scaler2\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:196\u001b[0m, in \u001b[0;36mrod_3D\u001b[1;34m(x, gm, median, scaler1, scaler2)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=177'>178</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=178'>179</a>\u001b[0m \u001b[39mFind ROD scores for 3D Data.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=179'>180</a>\u001b[0m \u001b[39mnote that gm, scaler1 and scaler2 will be returned \"as they are\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=192'>193</a>\u001b[0m \u001b[39mdecision_scores, gm, scaler1, scaler2\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=193'>194</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=194'>195</a>\u001b[0m \u001b[39m# find the geometric median if it is not already fit\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=195'>196</a>\u001b[0m gm \u001b[39m=\u001b[39m geometric_median(x) \u001b[39mif\u001b[39;00m gm \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m gm\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=196'>197</a>\u001b[0m \u001b[39m# find its norm and center data around it\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=197'>198</a>\u001b[0m norm_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(gm)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:80\u001b[0m, in \u001b[0;36mgeometric_median\u001b[1;34m(x, eps)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=77'>78</a>\u001b[0m Dinvs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(Dinv)\n\u001b[0;32m     <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=78'>79</a>\u001b[0m W \u001b[39m=\u001b[39m Dinv \u001b[39m/\u001b[39m Dinvs\n\u001b[1;32m---> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=79'>80</a>\u001b[0m T \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(W \u001b[39m*\u001b[39m points[non_zeros], \u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=80'>81</a>\u001b[0m num_zeros \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(points) \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39msum(non_zeros)\n\u001b[0;32m     <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/pyod/models/rod.py?line=81'>82</a>\u001b[0m \u001b[39mif\u001b[39;00m num_zeros \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n",
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n",
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n",
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n",
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n",
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n",
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "outlier_scores = calculate_rod_outlier_scores(data)\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(outlier_scores, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.45\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIF 2023\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.iforest import IForest\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_dif_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the DIF model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply DIF from pyod\n",
    "    dif = IForest()\n",
    "    dif.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = dif.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_dif_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate ECOD outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.043795620437956206\n",
      "Recall: 0.2222222222222222\n",
      "AUC: 0.6220500860680771\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.24489795918367352\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.058823529411764705\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8323293172690763\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "outlier_scores = calculate_dif_outlier_scores(data)\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(outlier_scores, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.54\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUOD 2021\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.suod import SUOD\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_suod_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the SUOD model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply SUOD from pyod\n",
    "    suod = SUOD()\n",
    "    suod.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = suod.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_suod_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.043795620437956206\n",
      "Recall: 0.2222222222222222\n",
      "AUC: 0.6160253206729969\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6938775510204082\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.058823529411764705\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8042168674698795\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "outlier_scores = calculate_suod_outlier_scores(data)\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(outlier_scores, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.09090909090909091\n",
      "Recall: 0.5\n",
      "AUC: 0.655\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LUNAR 2022\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.lunar import LUNAR\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_lunar_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the lunar model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply LUNAR from pyod\n",
    "    lunar = LUNAR()\n",
    "    lunar.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = lunar.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_lunar_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.029197080291970802\n",
      "Recall: 0.14814814814814814\n",
      "AUC: 0.4962518740629685\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.5102040816326531\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.029411764705882353\n",
      "Recall: 0.16666666666666666\n",
      "AUC: 0.7439759036144578\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6222222222222222\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "outlier_scores = calculate_lunar_outlier_scores(data)\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(outlier_scores, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.605\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b667cebad148e7b094a58ee81f940c685de1dd70a003a9ccdca4a5792431bee5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
