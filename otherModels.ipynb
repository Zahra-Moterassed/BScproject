{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ECOD 2022\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.ecod import ECOD\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_ecod_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the ECOD model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply ECOD from pyod\n",
    "    ecod = ECOD()\n",
    "    ecod.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = ecod.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_ecod_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate ECOD outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.051094890510948905\n",
      "Recall: 0.25925925925925924\n",
      "AUC: 0.738047642845244\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.26530612244897955\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.058823529411764705\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8679718875502008\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "outlier_scores = calculate_ecod_outlier_scores(data)\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(outlier_scores, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COPOD 2020\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.copod import COPOD\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_copod_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the COPOD model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply COPOD from pyod\n",
    "    copod = COPOD()\n",
    "    copod.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = copod.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_copod_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate ECOD outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.051094890510948905\n",
      "Recall: 0.25925925925925924\n",
      "AUC: 0.6914598256427342\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.40816326530612246\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.058823529411764705\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.7966867469879517\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "outlier_scores = calculate_copod_outlier_scores(data)\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(outlier_scores, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.09090909090909091\n",
      "Recall: 0.5\n",
      "AUC: 0.605\n"
     ]
    }
   ],
   "source": [
    "# COPOD\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_copod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_copod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_copod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROD 2020\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.rod import ROD\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_rod_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the ROD model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply ROD from pyod\n",
    "    rod = ROD()\n",
    "    rod.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = rod.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_rod_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate ECOD outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.072992700729927\n",
      "Recall: 0.37037037037037035\n",
      "AUC: 0.7775556666111388\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6734693877551021\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Reduce to 50 dimensions for faster processing\n",
    "pca = PCA(n_components=100, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train_pca)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val_pca)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.058823529411764705\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8719879518072289\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n",
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n",
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n",
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n",
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n",
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n",
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\rod.py:203: RuntimeWarning: invalid value encountered in divide\n",
      "  np.arccos(np.clip(np.dot(_x, gm) / (v_norm * norm_), -1, 1)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "outlier_scores = calculate_rod_outlier_scores(data)\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(outlier_scores, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.45\n"
     ]
    }
   ],
   "source": [
    "# ROD\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_rod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_rod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_rod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIF 2023\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.iforest import IForest\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_dif_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the DIF model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply DIF from pyod\n",
    "    dif = IForest()\n",
    "    dif.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = dif.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_dif_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate ECOD outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.043795620437956206\n",
      "Recall: 0.2222222222222222\n",
      "AUC: 0.6220500860680771\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.24489795918367352\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.058823529411764705\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8323293172690763\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "outlier_scores = calculate_dif_outlier_scores(data)\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(outlier_scores, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.54\n"
     ]
    }
   ],
   "source": [
    "# DIF\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_dif_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_dif_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_dif_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUOD 2021\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.suod import SUOD\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_suod_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the SUOD model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply SUOD from pyod\n",
    "    suod = SUOD()\n",
    "    suod.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = suod.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_suod_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.043795620437956206\n",
      "Recall: 0.2222222222222222\n",
      "AUC: 0.6160253206729969\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6938775510204082\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.058823529411764705\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8042168674698795\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "outlier_scores = calculate_suod_outlier_scores(data)\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(outlier_scores, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "\n",
      "RandomForestRegressor()\n",
      "\n",
      "Precision: 0.09090909090909091\n",
      "Recall: 0.5\n",
      "AUC: 0.655\n"
     ]
    }
   ],
   "source": [
    "# SUOD\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_suod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_suod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_suod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LUNAR 2022\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.lunar import LUNAR\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_lunar_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the lunar model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply LUNAR from pyod\n",
    "    lunar = LUNAR()\n",
    "    lunar.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = lunar.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_lunar_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.029197080291970802\n",
      "Recall: 0.14814814814814814\n",
      "AUC: 0.4962518740629685\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.5102040816326531\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.029411764705882353\n",
      "Recall: 0.16666666666666666\n",
      "AUC: 0.7439759036144578\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6222222222222222\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "outlier_scores = calculate_lunar_outlier_scores(data)\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(outlier_scores, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.605\n"
     ]
    }
   ],
   "source": [
    "# LUNAR\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_lunar_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_lunar_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_lunar_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b667cebad148e7b094a58ee81f940c685de1dd70a003a9ccdca4a5792431bee5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
