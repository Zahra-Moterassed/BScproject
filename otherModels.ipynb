{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ECOD 2022\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.ecod import ECOD\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_ecod_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the ECOD model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply ECOD from pyod\n",
    "    ecod = ECOD()\n",
    "    ecod.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = ecod.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_ecod_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate ECOD outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Precision: 0.0511\n",
      "Recall: 0.2593\n",
      "AUC: 0.7380\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "AUC: 0.2653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\ecod.py:23: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  return np.nan_to_num(skew_sp(X, axis=axis))\n",
      "c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyod\\models\\ecod.py:23: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  return np.nan_to_num(skew_sp(X, axis=axis))\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Precision: 0.0588\n",
      "Recall: 0.3333\n",
      "AUC: 0.8680\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Precision: 0.2000\n",
      "Recall: 1.0000\n",
      "AUC: 0.9111\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Precision: 0.5000\n",
      "Recall: 1.0000\n",
      "AUC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Precision: 0.3333\n",
      "Recall: 1.0000\n",
      "AUC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m labels \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Split the data into training and validation sets (70% train, 30% validation)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate outlier scores on the training set\u001b[39;00m\n\u001b[0;32m     24\u001b[0m predicted_outlier_scores \u001b[38;5;241m=\u001b[39m calculate_ecod_outlier_scores(X_train)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=207'>208</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=208'>209</a>\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=209'>210</a>\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=210'>211</a>\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=211'>212</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=212'>213</a>\u001b[0m     ):\n\u001b[1;32m--> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=213'>214</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=214'>215</a>\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=215'>216</a>\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=216'>217</a>\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=217'>218</a>\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=218'>219</a>\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=219'>220</a>\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=220'>221</a>\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=221'>222</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=222'>223</a>\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/utils/_param_validation.py?line=223'>224</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2670\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2665'>2666</a>\u001b[0m         CVClass \u001b[39m=\u001b[39m ShuffleSplit\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2667'>2668</a>\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m-> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2669'>2670</a>\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X\u001b[39m=\u001b[39;49marrays[\u001b[39m0\u001b[39;49m], y\u001b[39m=\u001b[39;49mstratify))\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2671'>2672</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2672'>2673</a>\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2673'>2674</a>\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2674'>2675</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2675'>2676</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1746\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=1715'>1716</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=1716'>1717</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=1717'>1718</a>\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=1742'>1743</a>\u001b[0m \u001b[39mto an integer.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=1743'>1744</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=1744'>1745</a>\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=1745'>1746</a>\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=1746'>1747</a>\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2147\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2144'>2145</a>\u001b[0m class_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2145'>2146</a>\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmin(class_counts) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2146'>2147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2147'>2148</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe least populated class in y has only 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2148'>2149</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m member, which is too few. The minimum\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2149'>2150</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m number of groups for any class cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2150'>2151</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m be less than 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2151'>2152</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2153'>2154</a>\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m<\u001b[39m n_classes:\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2154'>2155</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2155'>2156</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe train_size = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m should be greater or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2156'>2157</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mequal to the number of classes = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   <a href='file:///c%3A/Users/asus/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_split.py?line=2157'>2158</a>\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "AUC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# ECOD\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File path to the dataset\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "\n",
    "# Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Calculate outlier scores on the training set\n",
    "predicted_outlier_scores = calculate_ecod_outlier_scores(X_train)\n",
    "        \n",
    "# Evaluate the performance on the validation set\n",
    "val_outlier_scores = calculate_ecod_outlier_scores(X_val)\n",
    "        \n",
    "# Evaluate the performance\n",
    "precision, recall, auc = evaluate_ecod_outlier_detection(val_outlier_scores, y_val)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COPOD 2020\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.copod import COPOD\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_copod_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the COPOD model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply COPOD from pyod\n",
    "    copod = COPOD()\n",
    "    copod.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = copod.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_copod_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate ECOD outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROD 2020\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.rod import ROD\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_rod_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the ROD model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply ROD from pyod\n",
    "    rod = ROD()\n",
    "    rod.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = rod.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_rod_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate ECOD outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIF 2023\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.iforest import IForest\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_dif_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the ROD model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply ROD from pyod\n",
    "    dif = DIF()\n",
    "    dif.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = dif.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_dif_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate ECOD outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUOD 2021\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.suod import SUOD\n",
    "from pyod.models.iforest import IForest\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_suod_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the SUOD model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply ROD from pyod\n",
    "    suod = SUOD()\n",
    "    suod.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = suod.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_suod_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LUNAR 2022\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.lunar import LUNAR\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def calculate_lunar_outlier_scores(data):\n",
    "    \"\"\"\n",
    "    Calculate outlier scores using the lunar model.\n",
    "\n",
    "    Args:\n",
    "        data: Input dataset (numpy array or pandas DataFrame).\n",
    "\n",
    "    Returns:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "    \"\"\"\n",
    "    # Apply ROD from pyod\n",
    "    lunar = LUNAR()\n",
    "    lunar.fit(data)\n",
    "\n",
    "    # Get the outlier scores\n",
    "    outlier_scores = lunar.decision_scores_  # higher score -> more outlier\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "def evaluate_lunar_outlier_detection(outlier_scores, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate outlier detection results using precision, recall, and AUC.\n",
    "\n",
    "    Args:\n",
    "        outlier_scores: Array of outlier scores.\n",
    "        ground_truth: Ground truth labels (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "        precision: Precision of the model.\n",
    "        recall: Recall of the model.\n",
    "        auc: AUC of the model.\n",
    "    \"\"\"\n",
    "    # Calculate precision, recall, and AUC\n",
    "    threshold = np.percentile(outlier_scores, 90)  # Setting threshold at the 90th percentile for demonstration\n",
    "    predictions = (outlier_scores >= threshold).astype(int)  # Classify as 1 if above threshold (outlier), else 0\n",
    "\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision, recall, auc\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b667cebad148e7b094a58ee81f940c685de1dd70a003a9ccdca4a5792431bee5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
