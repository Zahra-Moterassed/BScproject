{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"k-Nearest Neighbors Detector (kNN)\"\"\"\n",
    "\n",
    "# Importing necessary libraries\n",
    "from warnings import warn\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree, NearestNeighbors\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from .base import BaseDetector\n",
    "\n",
    "# kNN class inherits from BaseDetector, used for outlier detection based on the distance to nearest neighbors\n",
    "class KNN(BaseDetector):\n",
    "    \"\"\"kNN-based outlier detector.\n",
    "\n",
    "    Computes an outlier score based on the distance of a point to its k nearest neighbors.\n",
    "    Supports different methods for calculating outlier scores.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, contamination=0.1, n_neighbors=5, method='largest',\n",
    "                 radius=1.0, algorithm='auto', leaf_size=30,\n",
    "                 metric='minkowski', p=2, metric_params=None, n_jobs=1,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize KNN detector with various parameters.\n",
    "\n",
    "        Parameters:\n",
    "        - contamination: Proportion of outliers in the dataset.\n",
    "        - n_neighbors: Number of neighbors to use.\n",
    "        - method: Method for calculating outlier score.\n",
    "        - algorithm: Nearest neighbor search algorithm.\n",
    "        - metric: Distance metric for neighbor calculation.\n",
    "        \"\"\"\n",
    "        super(KNN, self).__init__(contamination=contamination)\n",
    "        \n",
    "        # Setting class attributes\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.method = method\n",
    "        self.radius = radius\n",
    "        self.algorithm = algorithm\n",
    "        self.leaf_size = leaf_size\n",
    "        self.metric = metric\n",
    "        self.p = p\n",
    "        self.metric_params = metric_params\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        # Warns user if algorithm is deprecated\n",
    "        if self.algorithm != 'auto' and self.algorithm != 'ball_tree':\n",
    "            warn('algorithm parameter is deprecated and will be removed in version 0.7.6. By default, ball_tree will be used.',\n",
    "                 FutureWarning)\n",
    "\n",
    "        # Initializing NearestNeighbors model\n",
    "        self.neigh_ = NearestNeighbors(n_neighbors=self.n_neighbors,\n",
    "                                       radius=self.radius,\n",
    "                                       algorithm=self.algorithm,\n",
    "                                       leaf_size=self.leaf_size,\n",
    "                                       metric=self.metric,\n",
    "                                       p=self.p,\n",
    "                                       metric_params=self.metric_params,\n",
    "                                       n_jobs=self.n_jobs,\n",
    "                                       **kwargs)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit the kNN detector on the dataset X.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input samples, numpy array.\n",
    "        - y: Not used; present for compatibility.\n",
    "\n",
    "        Returns:\n",
    "        - self: Fitted kNN detector object.\n",
    "        \"\"\"\n",
    "\n",
    "        # Validates input and fits the model on X\n",
    "        X = check_array(X)\n",
    "        self._set_n_classes(y)\n",
    "        self.neigh_.fit(X)\n",
    "\n",
    "        # Handling case where NearestNeighbors lacks a _tree attribute\n",
    "        if self.neigh_._tree is not None:\n",
    "            self.tree_ = self.neigh_._tree\n",
    "        else:\n",
    "            # Uses BallTree if metric_params are provided\n",
    "            if self.metric_params is not None:\n",
    "                self.tree_ = BallTree(X, leaf_size=self.leaf_size,\n",
    "                                      metric=self.metric,\n",
    "                                      **self.metric_params)\n",
    "            else:\n",
    "                self.tree_ = BallTree(X, leaf_size=self.leaf_size,\n",
    "                                      metric=self.metric)\n",
    "\n",
    "        # Finds distances to neighbors for each point\n",
    "        dist_arr, _ = self.neigh_.kneighbors(n_neighbors=self.n_neighbors,\n",
    "                                             return_distance=True)\n",
    "        dist = self._get_dist_by_method(dist_arr)\n",
    "\n",
    "        # Storing outlier scores and setting up decision threshold\n",
    "        self.decision_scores_ = dist.ravel()\n",
    "        self._process_decision_scores()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Calculate anomaly scores for input samples X.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input samples, numpy array.\n",
    "\n",
    "        Returns:\n",
    "        - anomaly_scores: Anomaly scores for each sample in X.\n",
    "        \"\"\"\n",
    "        # Checks if model has been fitted before calling this method\n",
    "        check_is_fitted(self, ['tree_', 'decision_scores_', 'threshold_', 'labels_'])\n",
    "        X = check_array(X)\n",
    "\n",
    "        # Initializing output scores\n",
    "        pred_scores = np.zeros([X.shape[0], 1])\n",
    "\n",
    "        # Calculate distance for each input sample to its k nearest neighbors\n",
    "        for i in range(X.shape[0]):\n",
    "            x_i = X[i, :].reshape(1, -1)\n",
    "            dist_arr, _ = self.tree_.query(x_i, k=self.n_neighbors)\n",
    "            dist = self._get_dist_by_method(dist_arr)\n",
    "            pred_scores[i, :] = dist[-1]\n",
    "\n",
    "        return pred_scores.ravel()\n",
    "\n",
    "    def _get_dist_by_method(self, dist_arr):\n",
    "        \"\"\"Determine outlier score based on distance calculation method.\n",
    "\n",
    "        Parameters:\n",
    "        - dist_arr: Distance array to k nearest neighbors.\n",
    "\n",
    "        Returns:\n",
    "        - dist: Computed outlier scores.\n",
    "        \"\"\"\n",
    "        # Returns outlier score based on chosen method: largest, mean, or median distance\n",
    "        if self.method == 'largest':\n",
    "            return dist_arr[:, -1]\n",
    "        elif self.method == 'mean':\n",
    "            return np.mean(dist_arr, axis=1)\n",
    "        elif self.method == 'median':\n",
    "            return np.median(dist_arr, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Index  Avg_Outlier_Score\n",
      "0      4522           0.808209\n",
      "1      1138           1.625060\n",
      "2      2605           1.073420\n",
      "3      5978           1.648697\n",
      "4      3871           1.608492\n",
      "...     ...                ...\n",
      "6796   3933           0.855732\n",
      "6797   6783           1.788556\n",
      "6798   5766           0.579464\n",
      "6799   1154           1.588354\n",
      "6800   2371           1.427185\n",
      "\n",
      "[6801 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def calculate_outlier_scores(data, n_samples=5, sample_size=0.8, n_neighbors=5):\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "\n",
    "    # Dictionary to store cumulative outlier scores and counts for each instance\n",
    "    outlier_scores = defaultdict(lambda: {'score': 0, 'count': 0})\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Create a random sample of the data\n",
    "        sample_indices = random.sample(range(data.shape[0]), int(sample_size * data.shape[0]))\n",
    "        sample_data = data_std[sample_indices]\n",
    "        \n",
    "        # Perform KNN\n",
    "        knn = NearestNeighbors(n_neighbors=n_neighbors + 1)\n",
    "        knn.fit(sample_data)\n",
    "        \n",
    "        # Compute distances to the k-nearest neighbors (excluding self)\n",
    "        distances, _ = knn.kneighbors(sample_data)\n",
    "        knn_scores = np.mean(distances[:, 1:], axis=1)  # Average distance to neighbors\n",
    "\n",
    "        # Store the outlier score in the dictionary\n",
    "        for idx, score in zip(sample_indices, knn_scores):\n",
    "            outlier_scores[idx]['score'] += score\n",
    "            outlier_scores[idx]['count'] += 1\n",
    "\n",
    "    # Calculate the average outlier score for each instance\n",
    "    avg_outlier_scores = {idx: scores['score'] / scores['count'] for idx, scores in outlier_scores.items()}\n",
    "    \n",
    "    # Convert to a DataFrame\n",
    "    outlier_scores_df = pd.DataFrame(list(avg_outlier_scores.items()), columns=['Index', 'Avg_Outlier_Score'])\n",
    "    \n",
    "    return outlier_scores_df\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Calculate combined outlier scores using min of LOF, ABOD, and KNN\n",
    "outlier_scores_df = calculate_outlier_scores(data, n_samples=15, sample_size=0.8, n_neighbors=20)\n",
    "print(outlier_scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Index  Avg_Outlier_Score\n",
      "0      5192           1.005503\n",
      "1      3702           1.093693\n",
      "2      4677           1.207639\n",
      "3      1503           1.082789\n",
      "4      3684           1.078337\n",
      "...     ...                ...\n",
      "6796   1597           0.965093\n",
      "6797   5122           1.019429\n",
      "6798   2540           1.018458\n",
      "6799   2896           1.088706\n",
      "6800    780           1.740018\n",
      "\n",
      "[6801 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.lof import LOF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def calculate_LOF_outlier_scores(data, n_samples=5, sample_size=0.8, n_neighbors=20):\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "\n",
    "    # Dictionary to store cumulative outlier scores and counts for each instance\n",
    "    outlier_scores = defaultdict(lambda: {'score': 0, 'count': 0})\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Create a random sample of the data\n",
    "        sample_indices = random.sample(range(data.shape[0]), int(sample_size * data.shape[0]))\n",
    "        sample_data = data_std[sample_indices]\n",
    "        \n",
    "        # Apply LOF from pyod\n",
    "        lof = LOF(n_neighbors=n_neighbors)\n",
    "        lof.fit(sample_data)\n",
    "        \n",
    "        # Get the outlier scores for the sampled data\n",
    "        sample_scores = lof.decision_scores_  # higher score -> more outlier\n",
    "        \n",
    "        # Store the outlier score in the dictionary\n",
    "        for idx, score in zip(sample_indices, sample_scores):\n",
    "            outlier_scores[idx]['score'] += score\n",
    "            outlier_scores[idx]['count'] += 1\n",
    "\n",
    "    # Calculate the average outlier score for each instance\n",
    "    avg_outlier_scores = {idx: scores['score'] / scores['count'] for idx, scores in outlier_scores.items()}\n",
    "    \n",
    "    # Convert to a DataFrame\n",
    "    outlier_scores_df = pd.DataFrame(list(avg_outlier_scores.items()), columns=['Index', 'Avg_Outlier_Score'])\n",
    "    \n",
    "    return outlier_scores_df\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Calculate combined outlier scores using min of LOF, ABOD, and KNN\n",
    "outlier_scores_df = calculate_LOF_outlier_scores(data, n_samples=15, sample_size=0.8, n_neighbors=20)\n",
    "print(outlier_scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Index  Avg_Outlier_Score\n",
      "0      210           1.736596\n",
      "1      196           1.155961\n",
      "2      105           1.270112\n",
      "3      188           1.029650\n",
      "4      193           1.089597\n",
      "..     ...                ...\n",
      "242    221           1.123230\n",
      "243    240           1.097034\n",
      "244    222           1.142997\n",
      "245    165           0.995672\n",
      "246    204           1.130212\n",
      "\n",
      "[247 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Calculate combined outlier scores using min of LOF, ABOD, and KNN\n",
    "outlier_scores_df = calculate_LOF_outlier_scores(data, n_samples=15, sample_size=0.8, n_neighbors=20)\n",
    "print(outlier_scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Index  Avg_Outlier_Score\n",
      "0      226          14.859557\n",
      "1      158           9.786686\n",
      "2      153          30.027396\n",
      "3       50          11.663622\n",
      "4      145          11.579079\n",
      "..     ...                ...\n",
      "242     16          10.793798\n",
      "243    131          12.492385\n",
      "244      1          17.041164\n",
      "245    208          16.840518\n",
      "246    210          22.146086\n",
      "\n",
      "[247 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Calculate combined outlier scores using min of LOF, ABOD, and KNN\n",
    "outlier_scores_df = calculate_outlier_scores(data, n_samples=15, sample_size=0.8, n_neighbors=20)\n",
    "print(outlier_scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Index  Avg_Outlier_Score\n",
      "0       87           0.975946\n",
      "1       55           1.095323\n",
      "2      134           0.980259\n",
      "3       99           0.981735\n",
      "4      128           1.105530\n",
      "..     ...                ...\n",
      "147    144           1.208109\n",
      "148     94           1.157261\n",
      "149     34           1.281596\n",
      "150     60           0.977629\n",
      "151     76           1.048944\n",
      "\n",
      "[152 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Calculate combined outlier scores using min of LOF, ABOD, and KNN\n",
    "outlier_scores_df = calculate_LOF_outlier_scores(data, n_samples=15, sample_size=0.8, n_neighbors=20)\n",
    "print(outlier_scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Index  Avg_Outlier_Score\n",
      "0      110           3.631841\n",
      "1      149           3.428687\n",
      "2      123           4.399089\n",
      "3      127           3.561160\n",
      "4       35           4.681719\n",
      "..     ...                ...\n",
      "147     38           5.142043\n",
      "148    140           2.900206\n",
      "149    102           5.187372\n",
      "150     22           2.607539\n",
      "151     37           3.523377\n",
      "\n",
      "[152 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Calculate combined outlier scores using min of LOF, ABOD, and KNN\n",
    "outlier_scores_df = calculate_outlier_scores(data, n_samples=15, sample_size=0.8, n_neighbors=20)\n",
    "print(outlier_scores_df)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b667cebad148e7b094a58ee81f940c685de1dd70a003a9ccdca4a5792431bee5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
