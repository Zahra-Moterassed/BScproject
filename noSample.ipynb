{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.knn import KNN\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def knn_outlier_detection(data, ground_truth, n_neighbors=20):\n",
    "    \"\"\"\n",
    "    Performs KNN outlier detection on the dataset and evaluates it using precision, recall, and AUC.\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy array): Input dataset of shape (n_samples, n_features).\n",
    "        ground_truth (numpy array or pd.Series): Ground truth labels (1 = outlier, 0 = normal).\n",
    "        n_neighbors (int): Number of neighbors for KNN.\n",
    "        contamination (float): Proportion of the dataset expected to be outliers.\n",
    "\n",
    "    Returns:\n",
    "        dict: Precision, recall, and AUC scores.\n",
    "    \"\"\"\n",
    "    # Standardize the dataset\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "\n",
    "    # Initialize the KNN model\n",
    "    knn = KNN(n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Fit the model\n",
    "    knn.fit(data_std)\n",
    "\n",
    "    # Get outlier scores and predictions\n",
    "    outlier_scores = knn.decision_scores_  # Outlier scores (higher is more anomalous)\n",
    "    predictions = knn.predict(data_std)   # Predictions (1 = outlier, 0 = normal)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision,recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.05389221556886228\n",
      "Recall: 0.2647058823529412\n",
      "AUC: 0.6709285777326686\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.04\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8565573770491803\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.05421686746987952\n",
      "Recall: 0.28125\n",
      "AUC: 0.7612537764350453\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.7966666666666667\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 0.6666666666666666\n",
      "AUC: 0.8484848484848484\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4\n",
      "Recall: 1.0\n",
      "AUC: 0.9976359338061466\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6482222222222221\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.lof import LOF\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def lof_outlier_detection(data, ground_truth, n_neighbors=20):\n",
    "    \"\"\"\n",
    "    Performs LOF outlier detection on the dataset and evaluates it using precision, recall, and AUC.\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy array): Input dataset of shape (n_samples, n_features).\n",
    "        ground_truth (numpy array or pd.Series): Ground truth labels (1 = outlier, 0 = normal).\n",
    "        n_neighbors (int): Number of neighbors for LOF.\n",
    "        contamination (float): Proportion of the dataset expected to be outliers.\n",
    "\n",
    "    Returns:\n",
    "        dict: Precision, recall, and AUC scores.\n",
    "    \"\"\"\n",
    "    # Standardize the dataset\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "\n",
    "    # Initialize the LOF model\n",
    "    lof = LOF(n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Fit the model\n",
    "    lof.fit(data_std)\n",
    "\n",
    "    # Get outlier scores and predictions\n",
    "    outlier_scores = lof.decision_scores_  # Outlier scores (higher is more anomalous)\n",
    "    predictions = lof.predict(data_std)   # Predictions (1 = outlier, 0 = normal)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision,recall, auc\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.06856187290969899\n",
      "Recall: 0.3014705882352941\n",
      "AUC: 0.7558470499977936\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.05\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8510928961748634\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.05442176870748299\n",
      "Recall: 0.25\n",
      "AUC: 0.7757930513595166\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6366666666666667\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.14285714285714285\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8080808080808081\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.42857142857142855\n",
      "Recall: 1.0\n",
      "AUC: 0.9893617021276595\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6048888888888888\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.abod import ABOD\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def abod_outlier_detection(data, ground_truth):\n",
    "    \"\"\"\n",
    "    Performs ABOD outlier detection on the dataset and evaluates it using precision, recall, and AUC.\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy array): Input dataset of shape (n_samples, n_features).\n",
    "        ground_truth (numpy array or pd.Series): Ground truth labels (1 = outlier, 0 = normal).\n",
    "        contamination (float): Proportion of the dataset expected to be outliers.\n",
    "\n",
    "    Returns:\n",
    "        dict: Precision, recall, and AUC scores.\n",
    "    \"\"\"\n",
    "    # Standardize the dataset\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "\n",
    "    # Initialize the ABOD model\n",
    "    abod = ABOD()\n",
    "    \n",
    "    # Fit the model\n",
    "    abod.fit(data_std)\n",
    "\n",
    "    # Get outlier scores and predictions\n",
    "    outlier_scores = abod.decision_scores_  # Outlier scores (higher is more anomalous)\n",
    "    predictions = abod.predict(data_std)   # Predictions (1 = outlier, 0 = normal)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return  precision, recall, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0715307582260372\n",
      "Recall: 0.36764705882352944\n",
      "AUC: 0.7733870967741935\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.034482758620689655\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.7909836065573771\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.053763440860215055\n",
      "Recall: 0.3125\n",
      "AUC: 0.7116125377643505\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.7333333333333334\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.09090909090909091\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.7070707070707071\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 0.9716312056737588\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.16666666666666666\n",
      "Recall: 1.0\n",
      "AUC: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.03571428571428571\n",
      "Recall: 0.2222222222222222\n",
      "AUC: 0.6888888888888889\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN LOF ABOD with avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def knn_lof_abod_avg_outlier_detection(data, ground_truth, contamination=0.1, n_neighbors=20):\n",
    "    \"\"\"\n",
    "    Combines ABOD, KNN, and LOF to calculate outlier scores and evaluates using precision, recall, and AUC.\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy array): Input dataset of shape (n_samples, n_features).\n",
    "        ground_truth (numpy array or pd.Series): Ground truth labels (1 = outlier, 0 = normal).\n",
    "        contamination (float): Proportion of the dataset expected to be outliers.\n",
    "        n_neighbors (int): Number of neighbors for KNN and LOF.\n",
    "\n",
    "    Returns:\n",
    "        dict: Precision, recall, and AUC scores.\n",
    "    \"\"\"\n",
    "    # Standardize the dataset\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "\n",
    "    # Initialize and fit ABOD\n",
    "    abod = ABOD(contamination=contamination)\n",
    "    abod.fit(data_std)\n",
    "    abod_scores = abod.decision_scores_  # Outlier scores from ABOD\n",
    "\n",
    "    # Initialize and fit KNN\n",
    "    knn = KNN(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    knn.fit(data_std)\n",
    "    knn_scores = knn.decision_scores_  # Outlier scores from KNN\n",
    "\n",
    "    # Initialize and fit LOF\n",
    "    lof = LOF(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    lof.fit(data_std)\n",
    "    lof_scores = lof.decision_scores_  # Outlier scores from LOF\n",
    "\n",
    "    # Normalize the scores for ABOD, KNN, and LOF\n",
    "    scaler = MinMaxScaler()\n",
    "    abod_scores_norm = scaler.fit_transform(abod_scores.reshape(-1, 1)).flatten()\n",
    "    knn_scores_norm = scaler.fit_transform(knn_scores.reshape(-1, 1)).flatten()\n",
    "    lof_scores_norm = scaler.fit_transform(lof_scores.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Combine the scores by averaging\n",
    "    combined_scores = (abod_scores_norm + knn_scores_norm + lof_scores_norm) / 3\n",
    "\n",
    "    # Predictions based on combined scores\n",
    "    threshold = np.percentile(combined_scores, 100 * (1 - contamination))  # Threshold for outliers\n",
    "    predictions = (combined_scores > threshold).astype(int)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, combined_scores)\n",
    "\n",
    "    return precision,recall, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0661764705882353\n",
      "Recall: 0.33088235294117646\n",
      "AUC: 0.7179658885309563\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with avg\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_avg_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.04\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8620218579234972\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with avg\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_avg_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.07692307692307693\n",
      "Recall: 0.40625\n",
      "AUC: 0.7845543806646524\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with avg\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_avg_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.75\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with avg\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_avg_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2857142857142857\n",
      "Recall: 0.6666666666666666\n",
      "AUC: 0.8232323232323231\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with avg\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_avg_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4\n",
      "Recall: 1.0\n",
      "AUC: 0.9929078014184397\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with avg\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_avg_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with avg\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_avg_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6519999999999999\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with avg\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_avg_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN LOF ABOD with max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def knn_lof_abod_max_outlier_detection(data, ground_truth, contamination=0.1, n_neighbors=20):\n",
    "    \"\"\"\n",
    "    Combines normalized outlier scores from ABOD, KNN, and LOF by taking the maximum score\n",
    "    and evaluates the result using precision, recall, and AUC.\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy array): Input dataset of shape (n_samples, n_features).\n",
    "        ground_truth (numpy array or pd.Series): Ground truth labels (1 = outlier, 0 = normal).\n",
    "        contamination (float): Proportion of the dataset expected to be outliers.\n",
    "        n_neighbors (int): Number of neighbors for KNN and LOF.\n",
    "\n",
    "    Returns:\n",
    "        dict: Precision, recall, and AUC scores.\n",
    "    \"\"\"\n",
    "    # Standardize the dataset\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "\n",
    "    # Initialize and fit ABOD\n",
    "    abod = ABOD(contamination=contamination)\n",
    "    abod.fit(data_std)\n",
    "    abod_scores = abod.decision_scores_\n",
    "\n",
    "    # Initialize and fit KNN\n",
    "    knn = KNN(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    knn.fit(data_std)\n",
    "    knn_scores = knn.decision_scores_\n",
    "\n",
    "    # Initialize and fit LOF\n",
    "    lof = LOF(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    lof.fit(data_std)\n",
    "    lof_scores = lof.decision_scores_\n",
    "\n",
    "    # Normalize the scores for ABOD, KNN, and LOF\n",
    "    scaler = MinMaxScaler()\n",
    "    abod_scores_norm = scaler.fit_transform(abod_scores.reshape(-1, 1)).flatten()\n",
    "    knn_scores_norm = scaler.fit_transform(knn_scores.reshape(-1, 1)).flatten()\n",
    "    lof_scores_norm = scaler.fit_transform(lof_scores.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Combine the scores by taking the maximum\n",
    "    combined_scores = np.maximum.reduce([abod_scores_norm, knn_scores_norm, lof_scores_norm])\n",
    "\n",
    "    # Predictions based on combined scores\n",
    "    threshold = np.percentile(combined_scores, 100 * (1 - contamination))  # Threshold for outliers\n",
    "    predictions = (combined_scores > threshold).astype(int)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, combined_scores)\n",
    "\n",
    "    return precision, recall, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.06764705882352941\n",
      "Recall: 0.3382352941176471\n",
      "AUC: 0.7733870967741935\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with max\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_max_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.04\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.7930327868852459\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with max\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_max_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.05917159763313609\n",
      "Recall: 0.3125\n",
      "AUC: 0.711631419939577\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with max\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_max_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.7333333333333334\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with max\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_max_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.7070707070707071\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with max\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_max_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 0.8333333333333334\n",
      "AUC: 0.9728132387706856\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with max\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_max_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with max\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_max_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0392156862745098\n",
      "Recall: 0.2222222222222222\n",
      "AUC: 0.6888888888888889\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with max\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_max_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN LOF ABOD with min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def knn_lof_abod_min_outlier_detection(data, ground_truth, contamination=0.1, n_neighbors=20):\n",
    "    \"\"\"\n",
    "    Combines normalized outlier scores from ABOD, KNN, and LOF by taking the maximum score\n",
    "    and evaluates the result using precision, recall, and AUC.\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy array): Input dataset of shape (n_samples, n_features).\n",
    "        ground_truth (numpy array or pd.Series): Ground truth labels (1 = outlier, 0 = normal).\n",
    "        contamination (float): Proportion of the dataset expected to be outliers.\n",
    "        n_neighbors (int): Number of neighbors for KNN and LOF.\n",
    "\n",
    "    Returns:\n",
    "        dict: Precision, recall, and AUC scores.\n",
    "    \"\"\"\n",
    "    # Standardize the dataset\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "\n",
    "    # Initialize and fit ABOD\n",
    "    abod = ABOD(contamination=contamination)\n",
    "    abod.fit(data_std)\n",
    "    abod_scores = abod.decision_scores_\n",
    "\n",
    "    # Initialize and fit KNN\n",
    "    knn = KNN(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    knn.fit(data_std)\n",
    "    knn_scores = knn.decision_scores_\n",
    "\n",
    "    # Initialize and fit LOF\n",
    "    lof = LOF(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    lof.fit(data_std)\n",
    "    lof_scores = lof.decision_scores_\n",
    "\n",
    "    # Normalize the scores for ABOD, KNN, and LOF\n",
    "    scaler = MinMaxScaler()\n",
    "    abod_scores_norm = scaler.fit_transform(abod_scores.reshape(-1, 1)).flatten()\n",
    "    knn_scores_norm = scaler.fit_transform(knn_scores.reshape(-1, 1)).flatten()\n",
    "    lof_scores_norm = scaler.fit_transform(lof_scores.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Combine the scores by taking the minimum\n",
    "    combined_scores = np.minimum.reduce([abod_scores_norm, knn_scores_norm, lof_scores_norm])\n",
    "\n",
    "    # Predictions based on combined scores\n",
    "    threshold = np.percentile(combined_scores, 100 * (1 - contamination))  # Threshold for outliers\n",
    "    predictions = (combined_scores > threshold).astype(int)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, combined_scores)\n",
    "\n",
    "    return precision, recall, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.06323529411764706\n",
      "Recall: 0.3161764705882353\n",
      "AUC: 0.7571797361104983\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with min\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_min_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.04\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8510928961748634\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with min\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_min_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.047337278106508875\n",
      "Recall: 0.25\n",
      "AUC: 0.7763783987915408\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with min\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_min_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6366666666666666\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with min\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_min_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2857142857142857\n",
      "Recall: 0.6666666666666666\n",
      "AUC: 0.8333333333333331\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with min\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_min_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4\n",
      "Recall: 1.0\n",
      "AUC: 0.9905437352245863\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with min\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_min_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with min\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_min_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6073333333333333\n"
     ]
    }
   ],
   "source": [
    "# KNN LOF ABOD with min\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_lof_abod_min_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b667cebad148e7b094a58ee81f940c685de1dd70a003a9ccdca4a5792431bee5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
