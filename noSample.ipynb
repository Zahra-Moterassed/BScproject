{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.knn import KNN\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def knn_outlier_detection(data, ground_truth, n_neighbors=20):\n",
    "    \"\"\"\n",
    "    Performs KNN outlier detection on the dataset and evaluates it using precision, recall, and AUC.\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy array): Input dataset of shape (n_samples, n_features).\n",
    "        ground_truth (numpy array or pd.Series): Ground truth labels (1 = outlier, 0 = normal).\n",
    "        n_neighbors (int): Number of neighbors for KNN.\n",
    "        contamination (float): Proportion of the dataset expected to be outliers.\n",
    "\n",
    "    Returns:\n",
    "        dict: Precision, recall, and AUC scores.\n",
    "    \"\"\"\n",
    "    # Standardize the dataset\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "\n",
    "    # Initialize the KNN model\n",
    "    knn = KNN(n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Fit the model\n",
    "    knn.fit(data_std)\n",
    "\n",
    "    # Get outlier scores and predictions\n",
    "    outlier_scores = knn.decision_scores_  # Outlier scores (higher is more anomalous)\n",
    "    predictions = knn.predict(data_std)   # Predictions (1 = outlier, 0 = normal)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision,recall, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.05389221556886228\n",
      "Recall: 0.2647058823529412\n",
      "AUC: 0.6709285777326686\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.04\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8565573770491803\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.05421686746987952\n",
      "Recall: 0.28125\n",
      "AUC: 0.7612537764350453\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.7966666666666667\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 0.6666666666666666\n",
      "AUC: 0.8484848484848484\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4\n",
      "Recall: 1.0\n",
      "AUC: 0.9976359338061466\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6482222222222221\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = knn_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.lof import LOF\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def lof_outlier_detection(data, ground_truth, n_neighbors=20):\n",
    "    \"\"\"\n",
    "    Performs LOF outlier detection on the dataset and evaluates it using precision, recall, and AUC.\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy array): Input dataset of shape (n_samples, n_features).\n",
    "        ground_truth (numpy array or pd.Series): Ground truth labels (1 = outlier, 0 = normal).\n",
    "        n_neighbors (int): Number of neighbors for LOF.\n",
    "        contamination (float): Proportion of the dataset expected to be outliers.\n",
    "\n",
    "    Returns:\n",
    "        dict: Precision, recall, and AUC scores.\n",
    "    \"\"\"\n",
    "    # Standardize the dataset\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "\n",
    "    # Initialize the LOF model\n",
    "    lof = LOF(n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Fit the model\n",
    "    lof.fit(data_std)\n",
    "\n",
    "    # Get outlier scores and predictions\n",
    "    outlier_scores = lof.decision_scores_  # Outlier scores (higher is more anomalous)\n",
    "    predictions = lof.predict(data_std)   # Predictions (1 = outlier, 0 = normal)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return precision,recall, auc\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.06856187290969899\n",
      "Recall: 0.3014705882352941\n",
      "AUC: 0.7558470499977936\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.05\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8510928961748634\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.05442176870748299\n",
      "Recall: 0.25\n",
      "AUC: 0.7757930513595166\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6366666666666667\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.14285714285714285\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.8080808080808081\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.42857142857142855\n",
      "Recall: 1.0\n",
      "AUC: 0.9893617021276595\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2\n",
      "Recall: 1.0\n",
      "AUC: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.6048888888888888\n"
     ]
    }
   ],
   "source": [
    "# LOF\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = lof_outlier_detection(data, labels, n_neighbors=20)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.abod import ABOD\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def abod_outlier_detection(data, ground_truth):\n",
    "    \"\"\"\n",
    "    Performs ABOD outlier detection on the dataset and evaluates it using precision, recall, and AUC.\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy array): Input dataset of shape (n_samples, n_features).\n",
    "        ground_truth (numpy array or pd.Series): Ground truth labels (1 = outlier, 0 = normal).\n",
    "        contamination (float): Proportion of the dataset expected to be outliers.\n",
    "\n",
    "    Returns:\n",
    "        dict: Precision, recall, and AUC scores.\n",
    "    \"\"\"\n",
    "    # Standardize the dataset\n",
    "    scaler = StandardScaler()\n",
    "    data_std = scaler.fit_transform(data)\n",
    "\n",
    "    # Initialize the ABOD model\n",
    "    abod = ABOD()\n",
    "    \n",
    "    # Fit the model\n",
    "    abod.fit(data_std)\n",
    "\n",
    "    # Get outlier scores and predictions\n",
    "    outlier_scores = abod.decision_scores_  # Outlier scores (higher is more anomalous)\n",
    "    predictions = abod.predict(data_std)   # Predictions (1 = outlier, 0 = normal)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision = precision_score(ground_truth, predictions)\n",
    "    recall = recall_score(ground_truth, predictions)\n",
    "    auc = roc_auc_score(ground_truth, outlier_scores)\n",
    "\n",
    "    return  precision, recall, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0715307582260372\n",
      "Recall: 0.36764705882352944\n",
      "AUC: 0.7733870967741935\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Annthyroid_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Annthyroid\\\\Annthyroid_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.034482758620689655\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.7909836065573771\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Arrhythmia_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Arrhythmia\\\\Arrhythmia_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.053763440860215055\n",
      "Recall: 0.3125\n",
      "AUC: 0.7116125377643505\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Cardiotocography_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Cardiotocography\\\\Cardiotocography_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "AUC: 0.7333333333333334\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: HeartDisease_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\HeartDisease\\\\HeartDisease_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.09090909090909091\n",
      "Recall: 0.3333333333333333\n",
      "AUC: 0.7070707070707071\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Hepatitis_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Hepatitis\\\\Hepatitis_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3333333333333333\n",
      "Recall: 1.0\n",
      "AUC: 0.9716312056737588\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Lymphography_withoutdupl_norm_1ofn.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Lymphography\\\\Lymphography_withoutdupl_norm_1ofn.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-2].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -2].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.16666666666666666\n",
      "Recall: 1.0\n",
      "AUC: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Parkinson_withoutdupl_norm_05_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Parkinson\\\\Parkinson_withoutdupl_norm_05_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.03571428571428571\n",
      "Recall: 0.2222222222222222\n",
      "AUC: 0.6888888888888889\n"
     ]
    }
   ],
   "source": [
    "# ABOD\n",
    "# dataset: Pima_withoutdupl_norm_02_v01.csv\n",
    "\n",
    "file_path = \"G:\\\\Nazanin\\\\B project\\\\code\\\\dataset\\\\Pima\\\\Pima_withoutdupl_norm_02_v01.csv\"\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Separate data (all columns except the last)\n",
    "data = df.iloc[:, :-1].values\n",
    "    \n",
    "    # Separate labels (last column)\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "# Evaluate the outlier detection performance\n",
    "precision, recall, auc = abod_outlier_detection(data, labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b667cebad148e7b094a58ee81f940c685de1dd70a003a9ccdca4a5792431bee5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
